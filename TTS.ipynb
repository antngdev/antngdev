{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antngdev/antngdev/blob/main/TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv6wKD48of3x"
      },
      "source": [
        "# 🔥🔥🔥**viXTTS Demo**🗣️🗣️🗣️\n",
        "\n",
        "Demo này giúp bạn chạy viXTTS miễn phí trên Google Colab!\n",
        "Xem thông tin mô hình tại [đây](https://huggingface.co/capleaf/viXTTS)\n",
        "\n",
        "Bạn có thể dùng demo này với mục đích:\n",
        "- ✅Mục đích cá nhân, học tập, nghiên cứu, thử nghiệm\n",
        "\n",
        "Bạn **KHÔNG** được dùng demo này với mục đích:\n",
        "- ❌Mục đích trái đạo đức, vi phạm pháp luật Việt Nam\n",
        "- ❌Tạo ra nội dung gây thù ghét, kỳ thị, bạo lực hoặc nội dung vi phạm bản quyền\n",
        "- ❌Giả mạo danh tính hoặc gây hiểu nhầm rằng nội dung được tạo ra bởi một cá nhân hoặc tổ chức khác"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kIEFgM3gnEZm",
        "outputId": "8908c7d1-17a2-43eb-9332-ff93d617a893",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 22 04:28:49 PM +07 2024\n",
            " > Cài đặt thư viện...\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building editable for TTS (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.16 requires numpy>=1.24, but you'll have numpy 1.22.0 which is incompatible.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you'll have numpy 1.22.0 which is incompatible.\n",
            "arviz 0.19.0 requires numpy>=1.23.0, but you'll have numpy 1.22.0 which is incompatible.\n",
            "astropy 6.1.4 requires numpy>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "bigframes 1.22.0 requires numpy>=1.24.0, but you'll have numpy 1.22.0 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you'll have numpy 1.22.0 which is incompatible.\n",
            "contourpy 1.3.0 requires numpy>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you'll have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you'll have pandas 1.5.3 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you'll have numpy 1.22.0 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you'll have numpy 1.22.0 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you'll have numpy 1.22.0 which is incompatible.\n",
            "librosa 0.10.2.post1 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you'll have numpy 1.22.0 which is incompatible.\n",
            "mizani 0.11.4 requires numpy>=1.23.0, but you'll have numpy 1.22.0 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you'll have pandas 1.5.3 which is incompatible.\n",
            "numexpr 2.10.1 requires numpy>=1.23.0, but you'll have numpy 1.22.0 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you'll have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.13.6 requires numpy>=1.23.0, but you'll have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you'll have pandas 1.5.3 which is incompatible.\n",
            "pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "scikit-image 0.24.0 requires numpy>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you'll have numpy 1.22.0 which is incompatible.\n",
            "statsmodels 0.14.4 requires numpy<3,>=1.22.3, but you'll have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you'll have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.9.0 requires numpy>=1.24, but you'll have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.9.0 requires pandas>=2.1, but you'll have pandas 1.5.3 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires numpy>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "gruut 2.2.3 requires networkx<3.0.0,>=2.5.0, but you'll have networkx 3.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m600.9/600.9 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for cutlet (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.22.0 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 2.1.2 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.1.2 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.2 which is incompatible.\n",
            "gruut 2.2.3 requires networkx<3.0.0,>=2.5.0, but you have networkx 3.4.1 which is incompatible.\n",
            "gruut 2.2.3 requires numpy<2.0.0,>=1.19.0, but you have numpy 2.1.2 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.2 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pytensor 2.25.5 requires numpy<2,>=1.17.0, but you have numpy 2.1.2 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.2 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.2 which is incompatible.\n",
            "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.2/113.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.8/568.8 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.22.0 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 1.26.4 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "gruut 2.2.3 requires networkx<3.0.0,>=2.5.0, but you have networkx 3.4.1 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m > Tải mô hình...\n"
          ]
        }
      ],
      "source": [
        "# @title 1. ⚙️ **Cài đặt**\n",
        "# @markdown 👈Nhấn nút này để cài đặt (~5 phút)\n",
        "# Change timezone to Vietnam\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/Asia/Ho_Chi_Minh /etc/localtime\n",
        "!date\n",
        "\n",
        "print(\" > Cài đặt thư viện...\")\n",
        "!rm -rf TTS/\n",
        "!git clone --branch add-vietnamese-xtts -q https://github.com/thinhlpg/TTS.git\n",
        "!pip install --use-deprecated=legacy-resolver -q -e TTS\n",
        "!pip install deepspeed -q\n",
        "!pip install -q vinorm==2.0.7\n",
        "!pip install -q cutlet\n",
        "!pip install -q unidic==1.1.0\n",
        "!pip install -q underthesea\n",
        "!pip install -q gradio==4.35\n",
        "!pip install deepfilternet==0.5.6 -q\n",
        "\n",
        "import os\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "\n",
        "os.system(\"python -m unidic download\")\n",
        "print(\" > Tải mô hình...\")\n",
        "snapshot_download(repo_id=\"thinhlpg/viXTTS\",\n",
        "                  repo_type=\"model\",\n",
        "                  local_dir=\"model\")\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\" > ✅ Cài đặt hoàn tất, bạn hãy chạy tiếp các bước tiếp theo nhé!\")\n",
        "quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGSVcv3xuWWi"
      },
      "outputs": [],
      "source": [
        "# The inference code is adopted from https://github.com/coqui-ai/TTS/blob/dev/TTS/demos/xtts_ft_demo/xtts_demo.py\n",
        "# @title 2. 🤗 **Sử dụng**\n",
        "# @markdown 👈 Nhấn để chạy.\n",
        "# @markdown Nếu gặp lỗi thì cũng nhấn nút này nhé!\n",
        "\n",
        "# @markdown Lần đầu chạy sẽ hơi lâu, bạn chờ tí nhé!\n",
        "\n",
        "# @markdown Kết quả sẽ được lưu vào `/content/output`\n",
        "\n",
        "# @markdown Chọn ngôn ngữ:\n",
        "language = \"Tiếng Việt\" # @param [\"Tiếng Việt\", \"Tiếng Anh\",\"Tiếng Tây Ban Nha\", \"Tiếng Pháp\",\"Tiếng Đức\",\"Tiếng Ý\", \"Tiếng Bồ Đào Nha\", \"Tiếng Ba Lan\", \"Tiếng Thổ Nhĩ Kỳ\", \"Tiếng Nga\", \"Tiếng Hà Lan\", \"Tiếng Séc\", \"Tiếng Ả Rập\", \"Tiếng Trung (giản thể)\", \"Tiếng Nhật\", \"Tiếng Hungary\", \"Tiếng Hàn\", \"Tiếng Hindi\"]\n",
        "# @markdown Văn bản để đọc. Độ dài tối thiểu mỗi câu nên từ 10 từ để đặt kết quả tốt nhất.\n",
        "input_text =\"Xin chào, tôi là một công cụ có khả năng chuyển đổi văn bản thành giọng nói tự nhiên, được phát triển bởi nhóm Nón lá. Tôi có thể hổ trợ người khiếm thị,  đọc sách nói, làm trợ lý ảo, review phim, làm waifu để an ủi bạn, và phục vụ nhiều mục đích khác.\" # @param {type:\"string\"}\n",
        "# @markdown Chọn giọng mẫu:\n",
        "reference_audio = \"model/vi_sample.wav\" # @param [ \"model/user_sample.wav\",  \"model/vi_sample.wav\",  \"model/samples/nam-calm.wav\",  \"model/samples/nam-cham.wav\",  \"model/samples/nam-nhanh.wav\",  \"model/samples/nam-truyen-cam.wav\",  \"model/samples/nu-calm.wav\",  \"model/samples/nu-cham.wav\",  \"model/samples/nu-luu-loat.wav\",  \"model/samples/nu-nhan-nha.wav\",  \"model/samples/nu-nhe-nhang.wav\"]\n",
        "# @markdown Tự động chuẩn hóa chữ (VD: 20/11 -> hai mươi tháng mười một)\n",
        "normalize_text = True # @param {type:\"boolean\"}\n",
        "# @markdown In chi tiết xử lý\n",
        "verbose = True # @param {type:\"boolean\"}\n",
        "# @markdown Lưu từng câu thành file riêng lẻ.\n",
        "output_chunks = True # @param {type:\"boolean\"}\n",
        "\n",
        "from IPython.display import clear_output\n",
        "def cry_and_quit():\n",
        "    clear_output()\n",
        "    print(\"> Lỗi rồi huhu 😭😭, bạn hãy nhấn chạy lại phần này nhé!\")\n",
        "    quit()\n",
        "\n",
        "import os\n",
        "import string\n",
        "import unicodedata\n",
        "from datetime import datetime\n",
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "from underthesea import sent_tokenize\n",
        "from unidecode import unidecode\n",
        "\n",
        "try:\n",
        "    from vinorm import TTSnorm\n",
        "    from TTS.tts.configs.xtts_config import XttsConfig\n",
        "    from TTS.tts.models.xtts import Xtts\n",
        "except:\n",
        "    cry_and_quit()\n",
        "\n",
        "# Load model\n",
        "def clear_gpu_cache():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "def load_model(xtts_checkpoint, xtts_config, xtts_vocab):\n",
        "    clear_gpu_cache()\n",
        "    if not xtts_checkpoint or not xtts_config or not xtts_vocab:\n",
        "        return \"You need to run the previous steps or manually set the `XTTS checkpoint path`, `XTTS config path`, and `XTTS vocab path` fields !!\"\n",
        "    config = XttsConfig()\n",
        "    config.load_json(xtts_config)\n",
        "    XTTS_MODEL = Xtts.init_from_config(config)\n",
        "    print(\"Loading XTTS model! \")\n",
        "    XTTS_MODEL.load_checkpoint(config,\n",
        "                               checkpoint_path=xtts_checkpoint,\n",
        "                               vocab_path=xtts_vocab,\n",
        "                               use_deepspeed=True)\n",
        "    if torch.cuda.is_available():\n",
        "        XTTS_MODEL.cuda()\n",
        "\n",
        "    print(\"Model Loaded!\")\n",
        "    return XTTS_MODEL\n",
        "\n",
        "\n",
        "def get_file_name(text, max_char=50):\n",
        "    filename = text[:max_char]\n",
        "    filename = filename.lower()\n",
        "    filename = filename.replace(\" \", \"_\")\n",
        "    filename = filename.translate(str.maketrans(\"\", \"\", string.punctuation.replace(\"_\", \"\")))\n",
        "    filename = unidecode(filename)\n",
        "    current_datetime = datetime.now().strftime(\"%m%d%H%M%S\")\n",
        "    filename = f\"{current_datetime}_{filename}\"\n",
        "    return filename\n",
        "\n",
        "\n",
        "def calculate_keep_len(text, lang):\n",
        "    if lang in [\"ja\", \"zh-cn\"]:\n",
        "        return -1\n",
        "\n",
        "    word_count = len(text.split())\n",
        "    num_punct = (\n",
        "        text.count(\".\")\n",
        "        + text.count(\"!\")\n",
        "        + text.count(\"?\")\n",
        "        + text.count(\",\")\n",
        "    )\n",
        "\n",
        "    if word_count < 5:\n",
        "        return 15000 * word_count + 2000 * num_punct\n",
        "    elif word_count < 10:\n",
        "        return 13000 * word_count + 2000 * num_punct\n",
        "    return -1\n",
        "\n",
        "\n",
        "def normalize_vietnamese_text(text):\n",
        "    text = (\n",
        "        TTSnorm(text, unknown=False, lower=False, rule=True)\n",
        "        .replace(\"..\", \".\")\n",
        "        .replace(\"!.\", \"!\")\n",
        "        .replace(\"?.\", \"?\")\n",
        "        .replace(\" .\", \".\")\n",
        "        .replace(\" ,\", \",\")\n",
        "        .replace('\"', \"\")\n",
        "        .replace(\"'\", \"\")\n",
        "        .replace(\"AI\", \"Ây Ai\")\n",
        "        .replace(\"A.I\", \"Ây Ai\")\n",
        "    )\n",
        "    return text\n",
        "\n",
        "\n",
        "def run_tts(XTTS_MODEL, lang, tts_text, speaker_audio_file,\n",
        "            normalize_text= True,\n",
        "            verbose=False,\n",
        "            output_chunks=False):\n",
        "    \"\"\"\n",
        "    Run text-to-speech (TTS) synthesis using the provided XTTS_MODEL.\n",
        "\n",
        "    Args:\n",
        "        XTTS_MODEL: A pre-trained TTS model.\n",
        "        lang (str): The language of the input text.\n",
        "        tts_text (str): The text to be synthesized into speech.\n",
        "        speaker_audio_file (str): Path to the audio file of the speaker to condition the synthesis on.\n",
        "        normalize_text (bool, optional): Whether to normalize the input text. Defaults to True.\n",
        "        verbose (bool, optional): Whether to print verbose information. Defaults to False.\n",
        "        output_chunks (bool, optional): Whether to save synthesized speech chunks separately. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the synthesized audio file.\n",
        "    \"\"\"\n",
        "\n",
        "    if XTTS_MODEL is None or not speaker_audio_file:\n",
        "        return \"You need to run the previous step to load the model !!\", None, None\n",
        "\n",
        "    output_dir = \"./output\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    gpt_cond_latent, speaker_embedding = XTTS_MODEL.get_conditioning_latents(\n",
        "        audio_path=speaker_audio_file,\n",
        "        gpt_cond_len=XTTS_MODEL.config.gpt_cond_len,\n",
        "        max_ref_length=XTTS_MODEL.config.max_ref_len,\n",
        "        sound_norm_refs=XTTS_MODEL.config.sound_norm_refs,\n",
        "    )\n",
        "\n",
        "    if normalize_text and lang == \"vi\":\n",
        "        # Bug on google colab\n",
        "        try:\n",
        "            tts_text = normalize_vietnamese_text(tts_text)\n",
        "        except:\n",
        "            cry_and_quit()\n",
        "\n",
        "    if lang in [\"ja\", \"zh-cn\"]:\n",
        "        tts_texts = tts_text.split(\"。\")\n",
        "    else:\n",
        "        tts_texts = sent_tokenize(tts_text)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Text for TTS:\")\n",
        "        pprint(tts_texts)\n",
        "\n",
        "    wav_chunks = []\n",
        "    for text in tqdm(tts_texts):\n",
        "        if text.strip() == \"\":\n",
        "            continue\n",
        "\n",
        "        wav_chunk = XTTS_MODEL.inference(\n",
        "            text=text,\n",
        "            language=lang,\n",
        "            gpt_cond_latent=gpt_cond_latent,\n",
        "            speaker_embedding=speaker_embedding,\n",
        "            temperature=0.3,\n",
        "            length_penalty=1.0,\n",
        "            repetition_penalty=10.0,\n",
        "            top_k=30,\n",
        "            top_p=0.85,\n",
        "        )\n",
        "\n",
        "        # Quick hack for short sentences\n",
        "        keep_len = calculate_keep_len(text, lang)\n",
        "        wav_chunk[\"wav\"] = torch.tensor(wav_chunk[\"wav\"][:keep_len])\n",
        "\n",
        "        if output_chunks:\n",
        "            out_path = os.path.join(output_dir, f\"{get_file_name(text)}.wav\")\n",
        "            torchaudio.save(out_path, wav_chunk[\"wav\"].unsqueeze(0), 24000)\n",
        "            if verbose:\n",
        "                print(f\"Saved chunk to {out_path}\")\n",
        "\n",
        "        wav_chunks.append(wav_chunk[\"wav\"])\n",
        "\n",
        "    out_wav = torch.cat(wav_chunks, dim=0).unsqueeze(0)\n",
        "    out_path = os.path.join(output_dir, f\"{get_file_name(tts_text)}.wav\")\n",
        "    torchaudio.save(out_path, out_wav, 24000)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Saved final file to {out_path}\")\n",
        "\n",
        "    return out_path\n",
        "\n",
        "\n",
        "language_code_map = {\n",
        "    \"Tiếng Việt\": \"vi\",\n",
        "    \"Tiếng Anh\": \"en\",\n",
        "    \"Tiếng Tây Ban Nha\": \"es\",\n",
        "    \"Tiếng Pháp\": \"fr\",\n",
        "    \"Tiếng Đức\": \"de\",\n",
        "    \"Tiếng Ý\": \"it\",\n",
        "    \"Tiếng Bồ Đào Nha\": \"pt\",\n",
        "    \"Tiếng Ba Lan\": \"pl\",\n",
        "    \"Tiếng Thổ Nhĩ Kỳ\": \"tr\",\n",
        "    \"Tiếng Nga\": \"ru\",\n",
        "    \"Tiếng Hà Lan\": \"nl\",\n",
        "    \"Tiếng Séc\": \"cs\",\n",
        "    \"Tiếng Ả Rập\": \"ar\",\n",
        "    \"Tiếng Trung (giản thể)\": \"zh-cn\",\n",
        "    \"Tiếng Nhật\": \"ja\",\n",
        "    \"Tiếng Hungary\": \"hu\",\n",
        "    \"Tiếng Hàn\": \"ko\",\n",
        "    \"Tiếng Hindi\": \"hi\"\n",
        "}\n",
        "\n",
        "print(\"> Đang nạp mô hình...\")\n",
        "try:\n",
        "    if not vixtts_model:\n",
        "        vixtts_model = load_model(xtts_checkpoint=\"model/model.pth\",\n",
        "                                xtts_config=\"model/config.json\",\n",
        "                                xtts_vocab=\"model/vocab.json\")\n",
        "except:\n",
        "    vixtts_model = load_model(xtts_checkpoint=\"model/model.pth\",\n",
        "                                xtts_config=\"model/config.json\",\n",
        "                                xtts_vocab=\"model/vocab.json\")\n",
        "clear_output()\n",
        "print(\"> Đã nạp mô hình\")\n",
        "\n",
        "if not os.path.exists(reference_audio):\n",
        "    print(\"⚠️⚠️⚠️Bạn chưa tải file âm thanh lên. Hãy chọn giọng khác, hoặc tải file của bạn lên ở bên dưới.⚠️⚠️⚠️\")\n",
        "    audio_file=\"/content/model/vi_sample.wav\"\n",
        "else:\n",
        "    audio_file = run_tts(vixtts_model,\n",
        "            lang=language_code_map[language],\n",
        "            tts_text=input_text,\n",
        "            speaker_audio_file=reference_audio,\n",
        "            normalize_text=normalize_text,\n",
        "            verbose=verbose,\n",
        "            output_chunks=output_chunks,)\n",
        "\n",
        "from IPython.display import Audio\n",
        "Audio(audio_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "C7Bm9c2iTmpQ"
      },
      "outputs": [],
      "source": [
        "# @title 🎤 **Tải file âm thanh của bạn lên**\n",
        "# @markdown Để đạt chất lượng tốt nhất, hãy tham khảo file '/content/model/vi_sample.wav'\n",
        "# @\n",
        "import os\n",
        "import locale\n",
        "from google.colab import files\n",
        "\n",
        "denoise = True # @param {type:\"boolean\"}\n",
        "\n",
        "# Upload the audio file\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    # Convert the audio file to WAV format using ffmpeg\n",
        "    uploaded_dir = os.path.dirname(filename)\n",
        "    if denoise:\n",
        "        !deepFilter \"{filename}\"\n",
        "        !ffmpeg -i \"{filename.replace('.wav', '_DeepFilterNet3.wav')}\" -ac 1 -ar 22050 -vn /content/model/user_sample.wav -y -hide_banner -loglevel error\n",
        "        os.remove(filename.replace('.wav', '_DeepFilterNet3.wav'))\n",
        "    else:\n",
        "        !ffmpeg -i \"{filename}\" -ac 1 -ar 22050 -vn /content/model/user_sample.wav -y -hide_banner -loglevel error\n",
        "        os.remove(filename)\n",
        "    break\n",
        "\n",
        "from IPython.display import Audio, clear_output\n",
        "clear_output()\n",
        "print(\"> Đã tải file âm thanh lên\")\n",
        "Audio(\"/content/model/user_sample.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6sC6v6pNQVt5"
      },
      "outputs": [],
      "source": [
        "# @title ⏬ **Lưu kết quả vào Drive**\n",
        "# @markdown Chạy phần này để lưu kết quả vào Google Drive của bạn\n",
        "# @markdown `/content/drive/MyDrive/vixtts-output`\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save the output folder in \"vixtts-output\" in Google Drive, without overwriting existing files\n",
        "!cp -n -r /content/output/* /content/drive/MyDrive/vixtts-output\n",
        "print(\"> Đã lưu kết quả vào Google Drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7-X619YbX0n-"
      },
      "outputs": [],
      "source": [
        "# @title ⚠️ **Dọn kết quả**\n",
        "# @markdown Chạy phần này để xóa toàn bộ file trong `/content/output`\n",
        "import shutil\n",
        "shutil.rmtree('/content/output')\n",
        "print(\"Đã xóa toàn bộ file trong /content/output\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 📴 **Tắt Demo**\n",
        "# @markdown Khi chạy xong thì bạn hãy tắt demo để tiết kiệm GPU nhé!\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cvzEJ8c_PkRb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}